{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis - Alisha Siddiqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  HW 1  - Using tweets with the word 'trump' in it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data collection was done using a developer twitter account and running tweetering.py in spyder####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #Performing data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing Data cleaning using lower, strip and replace functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_clean=[] #creating an empty list\n",
    "file=open(\"Trump.txt\",\"r\") #open the Trump.txt file in read mode to analyze the twitter data.\n",
    "##Looping through the file to convert the strings to lowercase,remove all leading and trailing white spaces.\n",
    "for w in file: \n",
    "    w=w.lower()\n",
    "    w=w.strip()\n",
    "    w=w.replace(\"@\",\"\").replace(\":\",\"\").replace('rt',\"\").replace(\".\",\"\").\\\n",
    "    replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\"#\",\"\").replace(\"\\\\\",\"\").\\\n",
    "    replace(\"\\n\",\"\").replace(\"%\",\"\").replace(\"_\",\"\").replace(\"|\",\"\").replace(\"n\\'\",\"\").\\\n",
    "    replace(\"-\",\"\").replace(')',\"\").replace(\"(\",\"\")\n",
    "   \n",
    "    for w in w.split():\n",
    "       data_clean.append(w) #after splitting the strings append it to the data_clean list. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For further cleaning the data, using re.search function  \n",
    "#creating a temporary empty list\n",
    "a=[] \n",
    "#looping through the data which is cleaned above\n",
    "for i in range(len(data_clean)): \n",
    "#re.search function will search for the mentioned characters\n",
    "    if(re.search(r\"https|xe2|xf0|[0-9]\",data_clean[i]) is not None):    \n",
    "#if the match is true(not None)]will append the location of item to list a\n",
    "      a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using an if condition to not include the items with location in list a while looping through data\n",
    "data_clean=[data_clean[i] for i in range(len(data_clean)) if (i not in a)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"b'\", 'nanniquilts', 'brhodes', 'lawrence', 'ah', 'but', 'the', 'grifter', 'family', 'is', 'having', 'a', 'great', 'time', 'on', 'our', 'dime', 'how', 'is', 'this', 'for', 'impeachment', 'day', 'subduedradical', 'fakenewscnn', 'lowest', 'viewersnfakenewsmsnbc', 'lowest', 'viewers', 'nbiasmedia', 'brithume', 'marcthiessen', 'because', 'when', 'the', 'impeachment', 'was', 'in', 'the', 'house', 'bolton', 'originally', 'said', 'he', 'wouldt', 'democrats', 'say', 'there', 'is', '\"overwhelming\"', 'evidence', 'against', 'trumpnnyet', 'after', 'weeks', 'of', 'an', 'impeachment', 'inquirynnthousands', 'of', 'santiagomayer', 'a', 'picture', 'of', 'lev', 'parnas', 'a', 'possible', 'witness', 'with', 'pam', 'bondi', 'one', 'of', 'be', 'a', 'damn', 'shame', 'jaketapper', 'mffisher', 'zeitchikwapo', 'saudi', 'phone', 'because', 'trump', 'like', \"himb'\", 'tribelaw', 'turns', 'out', 'we', 'have', 'a', 'really', 'deep', 'bench', 'guys', 'every', 'one', 'of']\n"
     ]
    }
   ],
   "source": [
    "print(data_clean[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using text files(with negative, positive and stop words) for comparison with cleaned data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive =[]\n",
    "f1= open('positive.txt','r')\n",
    "for w in f1:\n",
    "    w=w.lower()\n",
    "    w=w.strip()\n",
    "    positive.append(w)\n",
    "len(positive)\n",
    "positive\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = []\n",
    "f2=open('negative1.txt','r')\n",
    "for x in f2:\n",
    "    x=x.lower()\n",
    "    x=x.strip()\n",
    "    negative.append(x)\n",
    "len(negative)\n",
    "negative\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=[]\n",
    "f3 = open('stopwords1.txt','r')\n",
    "for y in f3:\n",
    "    y = y.lower()\n",
    "    y = y.strip()\n",
    "    stop.append(y)\n",
    "len(stop)\n",
    "stop\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Comparing the lists above and performing analysis with the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing counter with 0 that will be used to count the no of +ve, -ve, others and stop words.\n",
    "stop_counter = 0\n",
    "negative_counter = 0\n",
    "pos_counter = 0\n",
    "positive_counter = 0\n",
    "others_counter = 0\n",
    "total_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping through the files to count the match and increase the counter by 1 respectively \n",
    "for w in data_clean:\n",
    "    if w in positive:\n",
    "        pos_counter +=1 \n",
    "    elif w in negative:\n",
    "            negative_counter +=1\n",
    "    elif w in stop:\n",
    "            stop_counter+=1\n",
    "    else:\n",
    "        others_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in data_clean:\n",
    "    if w in positive and w!=\"trump\":\n",
    "        positive_counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count =55075.00\n",
      "positive word count =1279\n",
      "negative word count =2126\n",
      "stop word count =22115\n",
      "other word count = 29555\n",
      "Ratio of positive to  total word count = 2.32%\n",
      "Ratio of negative to  total word count = 3.86%\n",
      "Ratio of stopwords to total word count = 40.15%\n",
      "Ratio of other word v/s total words ratio = 0.54\n",
      "Sum of all positive/negative words = 3405.00\n",
      "Ratio of positive/(postive + negative words) = 0.38\n"
     ]
    }
   ],
   "source": [
    "total_count = positive_counter+negative_counter+stop_counter+others_counter\n",
    "print(\"Total word count =%.2f\" %(total_count))\n",
    "print(\"positive word count =%d\" %positive_counter)\n",
    "print(\"negative word count =%d\" %negative_counter)\n",
    "print(\"stop word count =%d\" %stop_counter)\n",
    "print(\"other word count = %d\" %others_counter)\n",
    "\n",
    "\n",
    "print(\"Ratio of positive to  total word count = %.2f%%\" %((positive_counter/total_count)*100))\n",
    "print(\"Ratio of negative to  total word count = %.2f%%\" %((negative_counter/total_count)*100))\n",
    "print(\"Ratio of stopwords to total word count = %.2f%%\" %((stop_counter/total_count)*100))\n",
    "\n",
    "print(\"Ratio of other word v/s total words ratio = %.2f\" %(others_counter/(total_count)))\n",
    "\n",
    "print(\"Sum of all positive/negative words = %.2f\" %(positive_counter+negative_counter))\n",
    "\n",
    "print(\"Ratio of positive/(postive + negative words) = %.2f\" %(positive_counter/(positive_counter+negative_counter)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also haveto account for 'trump' word mistakenly being used as a positive word. #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the sum of all positive and negative words observed####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4. Performing sentiment analysis using the different word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The general sentiment of tweets is negative\n"
     ]
    }
   ],
   "source": [
    "if negative_counter > positive_counter:\n",
    "    print(\"The general sentiment of tweets is negative\")\n",
    "elif positive_counter > negative_counter:\n",
    "    print(\"The general sentiment of tweets is positive\")\n",
    "else:\n",
    "    print(\"The general sentiment of tweets is neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Calculating ratio of positive, negative and stop word with respect to total words####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of positive to  whole word count = 2.32%\n",
      "Ratio of negative to  whole word count = 3.86%\n",
      "Ratio of stopwords to whole word count = 40.15%\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of positive to  whole word count = %.2f%%\" %((positive_counter/total_count)*100))\n",
    "print(\"Ratio of negative to  whole word count = %.2f%%\" %((negative_counter/total_count)*100))\n",
    "print(\"Ratio of stopwords to whole word count = %.2f%%\" %((stop_counter/total_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative tweets increment by percentage value is 66.22%\n"
     ]
    }
   ],
   "source": [
    "#Calculating by what percentage is negative tweets exceeding positive tweets \n",
    "print (\"Negative tweets increment by percentage value is %.2f%%\" %(((negative_counter - positive_counter)/positive_counter) *100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Conclusion : Is the general sentiment positive or negative ? Strongly or weakly ? ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The negative word counter exceeds the positive word counter. Ratio of negative to  whole word count is 3.86%. Negative tweets increment from positive tweets by percentage value is 66.22%. Therefore, the sentiment is strongly negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## HW1- Part 2 Analysing trending tweet - \"Jeter\" ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data was collected from site https://trends24.in/united-states/  using Twitter API by running tweetering.py in spyder for  \"Jeter\"####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing re module for data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean=[] #creating an empty list\n",
    "file=open(\"Jeter.txt\",\"r\") #open the Trump.txt file in read mode to analyze the twitter data.\n",
    "##Looping through the file to convert the strings to lowercase,remove all leading and trailing white spaces.\n",
    "for w in file: \n",
    "    w=w.lower()\n",
    "    w=w.strip()\n",
    "    w=w.replace(\"@\",\"\").replace(\":\",\"\").replace('rt',\"\").replace(\".\",\"\").\\\n",
    "    replace(\",\",\"\").replace(\"!\",\"\").replace(\"?\",\"\").replace(\"#\",\"\").replace(\"\\\\\",\"\").\\\n",
    "    replace(\"\\n\",\"\").replace(\"%\",\"\").replace(\"_\",\"\").replace(\"|\",\"\").replace(\"n\\'\",\"\").\\\n",
    "    replace(\"-\",\"\").replace(')',\"\").replace(\"(\",\"\")\n",
    "   \n",
    "    for w in w.split():\n",
    "       data_clean.append(w) #after splitting the strings append it to the data_clean list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For further cleaning the data, using re.search function  \n",
    "#creating a temporary empty list\n",
    "a=[] \n",
    "#looping through the data which is cleaned above\n",
    "for i in range(len(data_clean)): \n",
    "#re.search function will search for the mentioned characters\n",
    "    if(re.search(r\"https|xe2|xf0|[0-9]\",data_clean[i]) is not None):    \n",
    "#if the match is true(not None)]will append the location of item to list a\n",
    "      a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean=[data_clean[i] for i in range(len(data_clean)) if (i not in a)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b\"', 'sposcenter', 'seasons', 'in', 'baseball', 'hall', 'of', 'fame', 'inductee', 'derek', \"jeter's\", 'career', 'was', 'full', 'of', 'memorable', 'moments', 'mlb', 'derek', 'jeter', 'inspired', 'a', 'generation', 'of', 'shostops', 'basedlockha', 'derek', 'jeter', 'is', 'clearly', 'a', 'unanimous', 'hall', 'of', 'famer', 'look', 'at', 'his', 'stats', 'sposcenter', 'seasons', 'in', 'baseball', 'hall', 'of', 'fame', 'inductee', 'derek', \"jeter's\", 'career', 'was', 'full', 'of', 'memorable', 'moments', 'goodtweetman', 'no', 'one', 'ever', 'talks', 'about', 'how', 'george', 'is', 'just', 'ganking', 'dingersb\"hey', 'everybody', 'derek', 'jeter', 'was', 'not', 'voted', 'in', 'unanimously', \"it's\", 'over', 'he', 'is', 'in', 'regardless', 'please', 'continue', 'with', 'your', 'dayn\"b\\'', 'without', 'george', 'constanza', 'who', 'knows', 'if', 'derek', 'jeter', 'makes', 'the', 'hall', 'of', 'famennvia', 'seinfeldtv']\n"
     ]
    }
   ],
   "source": [
    "print (data_clean[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using text files(with negative, positive and stop words) for comparison with cleaned data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive =[]\n",
    "f1= open('positive.txt','r')\n",
    "for w in f1:\n",
    "    w=w.lower()\n",
    "    w=w.strip()\n",
    "    positive.append(w)\n",
    "len(positive)\n",
    "positive\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = []\n",
    "f2=open('negative1.txt','r')\n",
    "for x in f2:\n",
    "    x=x.lower()\n",
    "    x=x.strip()\n",
    "    negative.append(x)\n",
    "len(negative)\n",
    "negative\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=[]\n",
    "f3 = open('stopwords1.txt','r')\n",
    "for y in f3:\n",
    "    y = y.lower()\n",
    "    y = y.strip()\n",
    "    stop.append(y)\n",
    "len(stop)\n",
    "stop[:2000]\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Comparing the lists above and performing analysis with the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_counter = 0\n",
    "negative_counter = 0\n",
    "positive_counter = 0\n",
    "others_counter = 0\n",
    "total_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in data_clean:\n",
    "    if w in positive:\n",
    "        positive_counter +=1 \n",
    "    elif w in negative:\n",
    "            negative_counter +=1\n",
    "    elif w in stop:\n",
    "            stop_counter+=1\n",
    "    else:\n",
    "        others_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count =25981.00\n",
      "positive word count =969\n",
      "negative word count =340\n",
      "stop word count =9805\n",
      "other word count = 14867\n",
      "Ratio of positive to  total word count = 3.73%\n",
      "Ratio of negative to  total word count = 1.31%\n",
      "Ratio of stopwords to total word count = 37.74%\n",
      "Ratio of other word v/s total words ratio = 0.57\n",
      "Sum of all positive/negative words = 1309.00\n",
      "Ratio of positive/(postive + negative words) = 0.74\n"
     ]
    }
   ],
   "source": [
    "total_count = positive_counter+negative_counter+stop_counter+others_counter\n",
    "print(\"Total word count =%.2f\" %(total_count))\n",
    "print(\"positive word count =%d\" %positive_counter)\n",
    "print(\"negative word count =%d\" %negative_counter)\n",
    "print(\"stop word count =%d\" %stop_counter)\n",
    "print(\"other word count = %d\" %others_counter)\n",
    "\n",
    "\n",
    "print(\"Ratio of positive to  total word count = %.2f%%\" %((positive_counter/total_count)*100))\n",
    "print(\"Ratio of negative to  total word count = %.2f%%\" %((negative_counter/total_count)*100))\n",
    "print(\"Ratio of stopwords to total word count = %.2f%%\" %((stop_counter/total_count)*100))\n",
    "\n",
    "print(\"Ratio of other word v/s total words ratio = %.2f\" %(others_counter/(total_count)))\n",
    "\n",
    "print(\"Sum of all positive/negative words = %.2f\" %(positive_counter+negative_counter))\n",
    "\n",
    "print(\"Ratio of positive/(postive + negative words) = %.2f\" %(positive_counter/(positive_counter+negative_counter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Analysing the word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The general sentiment of tweets is positive\n"
     ]
    }
   ],
   "source": [
    "if negative_counter > positive_counter:\n",
    "    print(\"The general sentiment of tweets is negative\")\n",
    "elif positive_counter > negative_counter:\n",
    "    print(\"The general sentiment of tweets is positive\")\n",
    "else:\n",
    "    print(\"The general sentiment of tweets is neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets increment by percentage value is 185.00%\n"
     ]
    }
   ],
   "source": [
    "print (\"Positive tweets increment by percentage value is %.2f%%\" %(((positive_counter - negative_counter)/negative_counter) *100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Conclusion : Is the general sentiment positive or negative ? Strongly or weakly ? ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The positive word counter exceeds the negative word counter. Ratio of positive to  total word count = 3.73%. Positive tweets increment negative tweets by percentage value of 185.00%. Therefore, the sentiment is extremely positive.#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
